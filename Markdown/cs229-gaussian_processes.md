# CS229 课程讲义中文翻译
CS229 Section notes

|原作者|翻译|
|---|---|
|Chuong B. Do|[XiaoDong_Wang](https://github.com/Dongzhixiao) |


|相关链接|
|---|
|[Github 地址](https://github。com/Kivy-CN/Stanford-CS-229-CN)|
|[知乎专栏](https://zhuanlan。zhihu。com/MachineLearn)|
|[斯坦福大学 CS229 课程网站](http://cs229。stanford。edu/)|
|[网易公开课中文字幕视频](http://open。163。com/movie/2008/1/M/C/M6SGF6VB4_M6SGHFBMC。html)|


### 高斯过程

#### 介绍

我们在本课程上半部分讨论的许多经典机器学习算法都符合以下模式：给定一组从未知分布中采样的独立同分布的示例训练集：

1. 求解一个凸优化问题，以确定数据单一的“最佳拟合”模型，并
2. 使用这个估计模型对未来的测试输入点做出“最佳猜测”的预测。

在本节的笔记中，我们将讨论一种不同的学习算法，称为**贝叶斯方法。** 与经典的学习算法不同，贝叶斯算法并不试图识别数据的“最佳匹配”模型(或者类似地，对新的测试输入做出“最佳猜测”的预测)。相反，其计算模型上的后验分布（或者类似地，计算新的输出的测试数据的后验预测分布）。这些分布提供了一种有用的方法来量化模型估计中的不确定性，并利用我们对这种不确定性的知识来对新的测试点做出更可靠的预测。

我们来关注下**回归**问题，即：目标是学习从某个$n$维向量的输入空间$\mathcal{X} = R^n$到实值目标的输出空间$\mathcal{Y} = R$的映射。特别地，我们将讨论一个基于核的完全贝叶斯回归算法，称为高斯过程回归。本节的笔记中涉及的内容主要包括我们之前在课堂上讨论过的许多不同主题（即线性回归$^1$的概率解释、贝叶斯方法$^2$、核方法$^3$和多元高斯$^4$的性质）。

>1 参见“[监督学习，判别算法](https://kivy-cn.github.io/Stanford-CS-229-CN/#/Markdown/cs229-notes1)”课程讲义。
>2 参见“[正则化和模型选择](https://kivy-cn.github.io/Stanford-CS-229-CN/#/Markdown/cs229-notes5)”课程讲义。
>3 参见“[支持向量机](https://kivy-cn.github.io/Stanford-CS-229-CN/#/Markdown/cs229-notes3)”课程讲义。
>4 参见“[因子分析](https://kivy-cn.github.io/Stanford-CS-229-CN/#/Markdown/cs229-notes9)”课程讲义。

本节的笔记后续内容的组织如下。在第1小节中，我们简要回顾了多元高斯分布及其性质。在第2小节中，我们简要回顾了贝叶斯方法在概率线性回归中的应用。第3小节给出了高斯过程的中心思想，第4小节给出了完整的高斯过程回归模型。

